import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
House_DF = pd.read_csv("USA_Housing.csv")
House_DF
House_DF.head()
House_DF.tail()
House_DF.describe()
House_DF.info(null_counts = True)
House_DF.columns
sns.pairplot(House_DF)
sns.distplot(House_DF['Price'])
sns.heatmap(House_DF.corr(), annot=True)
X = House_DF[['Avg. Area Income', 'Avg. Area House Age', 'Avg. Area Number of Rooms',
               'Avg. Area Number of Bedrooms', 'Area Population']]

Y = House_DF['Price']

from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4, random_state=101) 

from sklearn.linear_model import LinearRegression 

lm = LinearRegression() 

lm.fit(X_train,y_train) 

print(lm.intercept_)

coeff_df = pd.DataFrame(lm.coef_,X.columns,columns=['Coefficient'])
coeff_df

predictions = lm.predict(X_test) 
plt.scatter(y_test,predictions)
sns.distplot((y_test-predictions),bins=50);

from sklearn import metrics

print('MAE:', metrics.mean_absolute_error(y_test, predictions))
print('MSE:', metrics.mean_squared_error(y_test, predictions)) 
print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions))) 

#MAE is the easiest to understand because it’s the average error.
#MSE is more popular than MAE because MSE “punishes” larger errors, which tends to be useful in the real world.
#RMSE is even more popular than MSE because RMSE is interpretable in the “y” units.
#Mean Absolute Error (MAE) is the mean of the absolute value of the errors:
#Mean Squared Error (MSE) is the mean of the squared errors:
#Root Mean Squared Error (RMSE) is the square root of the mean of the squared errors:
